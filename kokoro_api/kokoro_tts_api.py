#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Kokoro TTS API å°è£…
æä¾›ç®€æ´çš„Pythonæ¥å£æ¥ä½¿ç”¨Kokoro TTSæ¨¡å‹
"""

import torch
import torch.nn.functional as F
import torchaudio
import numpy as np
from pathlib import Path
import logging
from typing import Optional, Dict, Any, List, Tuple
import time
import json

# Kokoro TTS ç›¸å…³å¯¼å…¥
try:
    import vocos
    from kokoro import generate
except ImportError as e:
    logging.warning(f"Kokoro TTS dependencies not found: {e}")
    logging.warning("Please install kokoro-tts package")

class KokoroTTSAPI:
    """
    Kokoro TTS API å°è£…ç±»
    
    æä¾›ç®€æ´çš„æ¥å£æ¥ä½¿ç”¨Kokoro TTSè¿›è¡Œä¸­æ–‡è¯­éŸ³åˆæˆ
    """
    
    def __init__(self, model_path: str, vocos_path: str, device: str = "auto"):
        """
        åˆå§‹åŒ–Kokoro TTS API
        
        Args:
            model_path: Kokoroæ¨¡å‹æ–‡ä»¶è·¯å¾„
            vocos_path: Vocoså£°ç å™¨æ¨¡å‹è·¯å¾„
            device: è®¡ç®—è®¾å¤‡ ('auto', 'cuda', 'cpu')
        """
        self.model_path = Path(model_path)
        self.vocos_path = Path(vocos_path)
        self.device = self._setup_device(device)
        self.model = None
        self.vocos = None
        self.is_initialized = False
        
        # éŸ³è‰²æ˜ å°„
        self.voice_mapping = {
            # å¥³æ€§éŸ³è‰²
            'female_calm': 'af_sarah',
            'female_warm': 'af_nicole', 
            'female_clear': 'af_bella',
            'female_gentle': 'af_sarah',
            'female_bright': 'af_nicole',
            
            # ç”·æ€§éŸ³è‰²
            'male_calm': 'am_adam',
            'male_warm': 'am_michael',
            'male_clear': 'am_adam', 
            'male_deep': 'am_michael',
            'male_bright': 'am_adam',
            
            # é»˜è®¤éŸ³è‰²
            'default': 'af_sarah'
        }
        
        self.logger = logging.getLogger(__name__)
    
    def _setup_device(self, device: str) -> torch.device:
        """
        è®¾ç½®è®¡ç®—è®¾å¤‡
        
        Args:
            device: è®¾å¤‡ç±»å‹
            
        Returns:
            torch.device: è®¡ç®—è®¾å¤‡
        """
        if device == "auto":
            if torch.cuda.is_available():
                device = "cuda"
            else:
                device = "cpu"
        
        return torch.device(device)
    
    def initialize(self) -> bool:
        """
        åˆå§‹åŒ–æ¨¡å‹
        
        Returns:
            bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        """
        try:
            self.logger.info(f"æ­£åœ¨åˆå§‹åŒ–Kokoro TTSæ¨¡å‹...")
            self.logger.info(f"è®¾å¤‡: {self.device}")
            self.logger.info(f"æ¨¡å‹è·¯å¾„: {self.model_path}")
            self.logger.info(f"Vocosè·¯å¾„: {self.vocos_path}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not self.model_path.exists():
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            if not self.vocos_path.exists():
                raise FileNotFoundError(f"Vocosæ–‡ä»¶ä¸å­˜åœ¨: {self.vocos_path}")
            
            # åŠ è½½Kokoroæ¨¡å‹
            self.logger.info("åŠ è½½Kokoroæ¨¡å‹...")
            self.model = torch.load(self.model_path, map_location=self.device)
            self.model.eval()
            
            # åŠ è½½Vocoså£°ç å™¨
            self.logger.info("åŠ è½½Vocoså£°ç å™¨...")
            self.vocos = vocos.Vocos.from_pretrained(str(self.vocos_path))
            self.vocos = self.vocos.to(self.device)
            self.vocos.eval()
            
            self.is_initialized = True
            self.logger.info("âœ… Kokoro TTSåˆå§‹åŒ–å®Œæˆ")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Kokoro TTSåˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def get_available_voices(self) -> Dict[str, List[str]]:
        """
        è·å–å¯ç”¨éŸ³è‰²åˆ—è¡¨
        
        Returns:
            Dict[str, List[str]]: æŒ‰ç±»åˆ«åˆ†ç»„çš„éŸ³è‰²åˆ—è¡¨
        """
        voices = {
            "å¥³æ€§éŸ³è‰²": [
                "female_calm",    # æ¸©å’Œå¥³å£°
                "female_warm",    # æ¸©æš–å¥³å£°
                "female_clear",   # æ¸…æ™°å¥³å£°
                "female_gentle",  # è½»æŸ”å¥³å£°
                "female_bright"   # æ˜äº®å¥³å£°
            ],
            "ç”·æ€§éŸ³è‰²": [
                "male_calm",      # æ¸©å’Œç”·å£°
                "male_warm",      # æ¸©æš–ç”·å£°
                "male_clear",     # æ¸…æ™°ç”·å£°
                "male_deep",      # æ·±æ²‰ç”·å£°
                "male_bright"     # æ˜äº®ç”·å£°
            ],
            "ç‰¹æ®ŠéŸ³è‰²": [
                "default"         # é»˜è®¤éŸ³è‰²
            ]
        }
        
        return voices
    
    def validate_voice(self, voice: str) -> str:
        """
        éªŒè¯å¹¶æ˜ å°„éŸ³è‰²åç§°
        
        Args:
            voice: éŸ³è‰²åç§°
            
        Returns:
            str: æ˜ å°„åçš„éŸ³è‰²åç§°
        """
        if voice in self.voice_mapping:
            return self.voice_mapping[voice]
        elif voice in self.voice_mapping.values():
            return voice
        else:
            self.logger.warning(f"æœªçŸ¥éŸ³è‰²: {voice}ï¼Œä½¿ç”¨é»˜è®¤éŸ³è‰²")
            return self.voice_mapping['default']
    
    def preprocess_text(self, text: str) -> str:
        """
        é¢„å¤„ç†æ–‡æœ¬
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            str: å¤„ç†åçš„æ–‡æœ¬
        """
        if not text or not text.strip():
            return ""
        
        # æ¸…ç†æ–‡æœ¬
        text = text.strip()
        
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = ' '.join(text.split())
        
        # ç¡®ä¿å¥å­ä»¥é€‚å½“çš„æ ‡ç‚¹ç»“å°¾
        if text and text[-1] not in 'ã€‚ï¼ï¼Ÿ.!?':
            text += 'ã€‚'
        
        return text
    
    def generate_speech(self, text: str, voice: str = "default", 
                       speed: float = 1.0, temperature: float = 0.7) -> Optional[Tuple[np.ndarray, int]]:
        """
        ç”Ÿæˆè¯­éŸ³
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            voice: éŸ³è‰²åç§°
            speed: è¯­é€Ÿå€ç‡ (0.5-2.0)
            temperature: æ¸©åº¦å‚æ•° (0.1-1.0)
            
        Returns:
            Optional[Tuple[np.ndarray, int]]: (éŸ³é¢‘æ•°æ®, é‡‡æ ·ç‡) æˆ– None
        """
        if not self.is_initialized:
            self.logger.error("æ¨¡å‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨initialize()")
            return None
        
        # é¢„å¤„ç†æ–‡æœ¬
        text = self.preprocess_text(text)
        if not text:
            self.logger.error("æ–‡æœ¬ä¸ºç©º")
            return None
        
        # éªŒè¯éŸ³è‰²
        voice = self.validate_voice(voice)
        
        # å‚æ•°èŒƒå›´æ£€æŸ¥
        speed = max(0.5, min(2.0, speed))
        temperature = max(0.1, min(1.0, temperature))
        
        try:
            self.logger.info(f"æ­£åœ¨åˆæˆè¯­éŸ³: {text[:50]}...")
            self.logger.info(f"éŸ³è‰²: {voice}, è¯­é€Ÿ: {speed}, æ¸©åº¦: {temperature}")
            
            start_time = time.time()
            
            # ä½¿ç”¨Kokoroç”Ÿæˆè¯­éŸ³
            with torch.no_grad():
                # è°ƒç”¨Kokoroçš„generateå‡½æ•°
                audio_tokens = generate(
                    model=self.model,
                    text=text,
                    voice=voice,
                    lang='zh',  # ä¸­æ–‡
                    temperature=temperature,
                    speed=speed,
                    device=self.device
                )
                
                # ä½¿ç”¨Vocosè§£ç éŸ³é¢‘
                if isinstance(audio_tokens, torch.Tensor):
                    audio_tokens = audio_tokens.unsqueeze(0)
                
                audio = self.vocos.decode(audio_tokens)
                
                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                audio = audio.cpu().numpy().squeeze()
                
            generation_time = time.time() - start_time
            audio_length = len(audio) / 24000  # å‡è®¾é‡‡æ ·ç‡ä¸º24kHz
            
            self.logger.info(f"âœ… è¯­éŸ³åˆæˆå®Œæˆ")
            self.logger.info(f"éŸ³é¢‘é•¿åº¦: {audio_length:.2f}ç§’")
            self.logger.info(f"ç”Ÿæˆæ—¶é—´: {generation_time:.2f}ç§’")
            self.logger.info(f"å®æ—¶å€ç‡: {audio_length/generation_time:.1f}x")
            
            return audio, 24000  # è¿”å›éŸ³é¢‘å’Œé‡‡æ ·ç‡
            
        except Exception as e:
            self.logger.error(f"âŒ è¯­éŸ³åˆæˆå¤±è´¥: {e}")
            return None
    
    def get_model_info(self) -> Dict[str, Any]:
        """
        è·å–æ¨¡å‹ä¿¡æ¯
        
        Returns:
            Dict[str, Any]: æ¨¡å‹ä¿¡æ¯å­—å…¸
        """
        info = {
            "model_path": str(self.model_path),
            "vocos_path": str(self.vocos_path),
            "device": str(self.device),
            "is_initialized": self.is_initialized,
            "available_voices": len(self.voice_mapping),
            "supported_languages": ["zh"],
            "sample_rate": 24000
        }
        
        if self.is_initialized and self.model is not None:
            try:
                # è·å–æ¨¡å‹å‚æ•°æ•°é‡
                total_params = sum(p.numel() for p in self.model.parameters())
                info["total_parameters"] = total_params
                info["trainable_parameters"] = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
            except:
                pass
        
        return info
    
    def cleanup(self):
        """
        æ¸…ç†èµ„æº
        """
        if self.model is not None:
            del self.model
            self.model = None
        
        if self.vocos is not None:
            del self.vocos
            self.vocos = None
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        self.is_initialized = False
        self.logger.info("ğŸ§¹ Kokoro TTSèµ„æºå·²æ¸…ç†")
    
    def __del__(self):
        """
        ææ„å‡½æ•°
        """
        self.cleanup()